# PRODIGY_ML_04
# ðŸ¤š Hand Gesture Recognition using CNN

This project implements a **real-time hand gesture recognition system** using a Convolutional Neural Network (CNN) trained on the [LeapGestRecog dataset](https://www.kaggle.com/datasets/gti-upm/leapgestrecog). It uses OpenCV to capture webcam input and TensorFlow to perform gesture classification live.

---

## ðŸ“¸ Demo
<img src="demo.gif" width="600">

---

## ðŸ“‚ Dataset
**LeapGestRecog** is a publicly available dataset from the **Gestures and Recognition group at the Technical University of Madrid (GTI-UPM)**.

- ðŸ“Ž **Source**: [https://www.kaggle.com/datasets/gti-upm/leapgestrecog](https://www.kaggle.com/datasets/gti-upm/leapgestrecog)
- ðŸ§‘â€ðŸ¤â€ðŸ§‘ 10 gesture classes
- ðŸ“· Over 20,000 grayscale images
- âœ‹ Captured using the Leap Motion Controller

> âœ… All credit for the dataset goes to the original creators at GTI-UPM.

---

## ðŸ§  Model Overview

- CNN with 3 convolutional layers + MaxPooling
- Trained on grayscale 100Ã—100 images
- Achieved over **99% test accuracy**
- Deployed using OpenCV for real-time prediction

---

## ðŸ§ª Technologies Used

- Python 3
- TensorFlow / Keras
- OpenCV
- NumPy
- Matplotlib

---

## ðŸš€ How to Use

### ðŸ§  Step 1: Train the Model in Colab

1. Open the training notebook in **Google Colab**.
2. Train the model using the LeapGestRecog dataset.
3. Save the model after training:
   ```python
   model.save("gesture_cnn_model.h5")
